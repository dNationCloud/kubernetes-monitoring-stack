#
# Copyright 2020 The dNation Kubernetes Monitoring Stack Authors. All Rights Reserved.
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Default values for dNation Kubernetes Monitoring Stack.
# Declare variables to be passed into helm chart dependencies.

## Override the default value of 'app' label used by k8s objects
##
nameOverride: ""

## Override the deployment namespace
##
namespaceOverride: ""

## Provide a name to substitute for the full names of resources
##
fullnameOverride: ""

######################################################################################################################
##
## Configure additional grafana datasources that will be provisioned as ConfigMaps
##
## ref: http://docs.grafana.org/administration/provisioning/#datasources
######################################################################################################################
grafanaDatasourcesAsConfigMap:
  cluster-metrics:
    - name: thanos
      isDefault: true
      type: prometheus
      access: proxy
      url: "http://{{ .Release.Name }}-thanos-query:9090"
  cluster-logs:
    - name: cluster-logs
      isDefault: false
      type: loki
      url: http://{{ .Release.Name }}-loki-gateway
      jsonData:
        httpHeaderName1: 'X-Scope-OrgID'
      secureJsonData:
        httpHeaderValue1: '1'

######################################################################################################################
##
## dNation-kubernetes-monitoring sub-chart configuration
##
## ref: https://github.com/dNationCloud/kubernetes-monitoring
######################################################################################################################
dnation-kubernetes-monitoring:
  enabled: true

  ## Deploy a Grafana dashboards and Prometheus rules for cluster monitoring
  ##
  clusterMonitoring:
    enabled: true

  ## Label of Grafana dashboard resource used for target discovery
  ##
  grafanaDashboards:
    labelGrafana:
      grafana_dashboard: '1'

  ## Label of Prometheus rule resource used for target discovery
  ##
  prometheusRules:
    labelPrometheus:
      prometheus_rule: '1'

######################################################################################################################
##
## Kube-prometheus-stack sub-chart configuration
##
## ref: https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack
######################################################################################################################
kube-prometheus-stack:
  enabled: true

  ## Provide a name to substitute for the full names of resources
  ##
  fullnameOverride: kube-prometheus

  ## Default rules for monitoring the cluster
  ##
  defaultRules:
    ## Labels for default rules
    ##
    labels:
      prometheus_rule: '1'

    ## Disable some kube-prometheus-stack default rules
    ## They are replaced by rules in the kubernetes monitoring project
    ##
    rules:
      general: false
      kubernetesStorage: false

    ## Add custom rule label
    ##
    additionalRuleLabels:
      alertgroup: Cluster

    ## TODO: Remove additionalRuleGroupLabels once the issue will be resolved
    ## see https://github.com/prometheus-community/helm-charts/issues/3396
    additionalRuleGroupLabels:
      kubeApiserverAvailability:
        alertgroup: null

  ## Deploy a Prometheus instance
  ##
  prometheus:
    prometheusSpec:
      serviceMonitorSelector:
        ## Match all dNation monitoring ServiceMonitors using the default match label setting `release=.Release.Name` OR
        ## match all ServiceMonitors with the static label `release=kubernetes-monitoring-servicemonitor`.
        ## The static label can be used for third-party ServiceMonitors deployed outside of this chart.
        ## If multiple instances of this monitoring are deployed within one Kubernetes environment,
        ## we recommend using different static labels for each instance to ensure separation of discovered ServiceMonitors.
        ##
        matchExpressions:
          - key: release
            operator: In
            values:
              - "{{ .Release.Name }}"
              - kubernetes-monitoring-servicemonitor

      podMonitorSelector:
        ## Match all dNation monitoring PodMonitors using the default match label setting `release=.Release.Name` OR
        ## match all PodMonitors with the static label `release=kubernetes-monitoring-podmonitor`.
        ## The static label can be used for third-party PodMonitors deployed outside of this chart.
        ## If multiple instances of this monitoring are deployed within one Kubernetes environment,
        ## we recommend using different static labels for each instance to ensure separation of discovered PodMonitors.
        ##
        matchExpressions:
          - key: release
            operator: In
            values:
              - "{{ .Release.Name }}"
              - kubernetes-monitoring-podmonitor

      ## !IMPORTANT: each cluster must have prometheus external label 'cluster' with unique value.
      ## This will be used as cluster discriminator when metrics are aggregated on observer cluster.
      ##
      externalLabels:
        cluster: observer-cluster

      ## PrometheusRules to be selected for target discovery
      ##
      ruleSelector:
        matchLabels:
          prometheus_rule: '1'

      ## Enable thanos sidecar
      ## https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#thanosspec
      ##
      thanos:
        logLevel: info
        objectStorageConfig: {}
    thanosService:
      enabled: true

  ## Component scraping scheduler
  ## ref: https://dnationcloud.github.io/kubernetes-monitoring/helpers/FAQ/#kubernetes-monitoring-shows-down-state-for-some-control-plane-components-are-control-plane-components-working-correctly
  ##
  kubeScheduler:
    service:
      port: 10259
      targetPort: 10259
    serviceMonitor:
      https: true
      ## Skip TLS certificate validation when scraping
      # insecureSkipVerify: true
      ## Name of the server to use when validating TLS certificate
      # serverName: null

  ## Component scraping controller manager
  ## ref: https://dnationcloud.github.io/kubernetes-monitoring/helpers/FAQ/#kubernetes-monitoring-shows-down-state-for-some-control-plane-components-are-control-plane-components-working-correctly
  ##
  kubeControllerManager:
    service:
      port: 10257
      targetPort: 10257
    serviceMonitor:
      https: true
      ## Skip TLS certificate validation when scraping
      # insecureSkipVerify: true
      ## Name of the server to use when validating TLS certificate
      # serverName: null

  ## Component scraping etcd
  ##
  kubeEtcd:
    ## Etcd service
    ## ref: https://dnationcloud.github.io/kubernetes-monitoring/helpers/FAQ/#kubernetes-monitoring-shows-down-state-for-some-control-plane-components-are-control-plane-components-working-correctly
    ##
    service:
      port: 2381
      targetPort: 2381

  ## Configuration for prometheus-node-exporter sub-chart
  ##
  prometheus-node-exporter:
    ## Extra args extended with `rootfs`file system
    ## For default extra args see ref: https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/values.yaml#L1991
    ##
    extraArgs:
    - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
    - --collector.filesystem.fs-types-exclude=^(rootfs|autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$

  ## Deploy a Grafana instance
  ##
  grafana:

    ## Security patch CVE-2025-4123 https://grafana.com/security/security-advisories/cve-2025-4123/
    ##
    image:
      registry: docker.io
      repository: grafana/grafana
      tag: "10.4.19-security-01"

    adminUser: "admin"
    adminPassword: "pass"
    ## Deploy default dashboards
    ##
    defaultDashboardsEnabled: false

    ## Define security context of grafana container
    ##
    securityContext:
      runAsNonRoot: false
      runAsUser: 0
      runAsGroup: 0
      fsGroup: 0

    ## Define command to be executed at startup of grafana container
    ##
    command:
    - "/bin/sh"
    - "-c"
    - "/etc/secrets/dnation_brand.sh && /run.sh"

    ## Inject dNation branding
    ##
    extraConfigmapMounts:
    - name: dnation-logo
      mountPath: /usr/share/grafana/public/img/dnation_logo.svg
      subPath: dnation_logo.svg
      configMap: dnation-logo
    - name: dnation-home
      mountPath: /usr/share/grafana/public/dashboards/home.json
      subPath: home.json
      configMap: dnation-home
    extraSecretMounts:
    - name: dnation-brand
      mountPath: /etc/secrets
      secretName: dnation-brand
      defaultMode: 0755

    ## Sidecar that collects the configmaps with specified label and stores them into the respective folders
    ##
    sidecar:
      dashboards:
        label: grafana_dashboard
        folder: /var/lib/grafana/dashboards/dnation
        provider:
          name: 'dNation'
          folder: 'dNation'
          disableDelete: false
          allowUiUpdates: true
      datasources:
        label: grafana_datasource
        defaultDatasourceEnabled: false

    plugins:
    - camptocamp-prometheus-alertmanager-datasource 1.0.0
    - grafana-polystat-panel 1.2.11

  ## Deploy an Alertmanager instance
  ##
  alertmanager:
    config:
      route:
        receiver: 'null'
        routes:
        - match:
            alertname: Watchdog
          receiver: 'null'
      inhibit_rules:
      - source_match:
          severity: 'critical'
        target_match:
          severity: 'warning'
        equal: ['alertname']

######################################################################################################################
##
## Thanos sub-chart configuration
##
## ref: https://github.com/bitnami/charts/tree/main/bitnami/thanos
######################################################################################################################
thanos:
  enabled: true
  queryFrontend:
    enabled: false
    extraFlags:
    - --query-range.split-interval=12h
    - --query-frontend.log-queries-longer-than=10s
    - --query-frontend.compress-responses
    - |-
      --query-range.response-cache-config="config":
        "max_size": "500MB"
        "max_size_items": 0
        "validity": 0s
      "type": "in-memory"
  query:
    extraFlags:
    - --query.auto-downsampling
    dnsDiscovery:
      sidecarsService: kube-prometheus-thanos-discovery
      sidecarsNamespace: "{{ .Release.Namespace }}"
  bucketweb:
    enabled: false
  compactor:
    enabled: false
    retentionResolutionRaw: 2d
    retentionResolution5m: 10d
    retentionResolution1h: 15d
    extraFlags:
    - --compact.concurrency=3
    - --downsample.concurrency=3
  storegateway:
    enabled: false
  ruler:
    enabled: false

######################################################################################################################
##
## Thanos query sidecar configuration
##
######################################################################################################################
thanosQueryEnvoySidecar:
  enabled: false

######################################################################################################################
##
## Loki sub-chart configuration
##
## Loki defaults to Simple Scalable Deployment (SSD) Mode.
## Fits well for small to medium size Loki deployments up to around few TB of logs per day.
## ref: https://github.com/grafana/loki/tree/main/production/helm/loki
## Config developed based on Loki [best-practices](https://grafana.com/docs/loki/latest/configure/bp-configure/) and
## dNation productive setup of Loki.
######################################################################################################################
loki:
  enabled: true
  ## The SimpleScalable deployment mode can scale up to a few TBs of logs per day.
  ##  If you go much beyond this, the Distributed (microservices) mode will be a better choice.
  ##
  deploymentMode: SimpleScalable
  auth_enabled: false
  loki:
    resultsCache:
      enabled: true  # Memcached based results-cache is enabled
    chunksCache:
      enabled: true  # Memcached based chunks-cache is enabled
    schemaConfig:
      configs:
        - from: 2024-06-01
          store: tsdb
          object_store: s3
          schema: v13
          index:
            prefix: loki_index_
            period: 24h
    limits_config:
      ## !Adjust for productive usage or remove if you want infinite retention!
      ## Validate also `compactor` settings
      ##
      retention_period: 48h  # 2days

    commonConfig:
      ## Use the memberlist key-value store instead of consul, read the related docs below for details:
      ## https://grafana.com/blog/2022/09/28/inside-the-migration-from-consul-to-memberlist-at-grafana-labs/
      ## https://grafana.com/docs/loki/latest/get-started/hash-rings/
      ##
      ring:
        kvstore:
          store: memberlist

    ingester:
      ## Use snappy compression instead of default gzip.
      ## It is focused on high speeds with ‘good enough’ compression ratio.
      ##
      chunk_encoding: snappy
      ## This section configures the ingester for deployments with infrequent log shipments to Loki.
      ## For medium to high-frequency log shipments, you can remove this section to use the default,
      ## more "real-world" ingester settings.
      ##
      ## How long chunks should sit in-memory with no updates before being flushed if
      ## they don't hit the max block size.
      ##
      chunk_idle_period: 6h
      ## The maximum duration of a timeseries chunk in memory. If a timeseries runs for
      ## longer than this, the current chunk will be flushed to the store and a new
      ## chunk created.
      ##
      max_chunk_age: 12h
      ## The targeted _uncompressed_ size in bytes of a chunk block When this threshold
      ## is exceeded the head block will be cut and compressed inside the chunk.
      ##
      chunk_block_size: 262144  # ~0.26MB
      ## A target _compressed_ size in bytes for chunks. This is a desired size not an
      ## exact size.
      ##
      chunk_target_size: 1572864  # ~1.5MB
      ## How long chunks should be retained in-memory after they've been flushed.
      ##
      chunk_retain_period: 1m

    querier:
      max_concurrent: 4  # Default is 4, if you have enough memory and CPU you can increase, reduce if OOMing
    compactor:
      retention_enabled: true
      delete_request_store: s3
      delete_request_cancel_period: 10m  # Don't wait 24h before processing the delete_request
  gateway:
    service:
      labels:
        ## TODO: Remove label once the issue below is resolved.
        ## Exclude scraping loki-gateway's non-existent /metrics endpoint,
        ## see https://github.com/grafana/loki/issues/13201
        ##
        prometheus.io/service-monitor: "false"
  backend:
    replicas: 3
  read:
    replicas: 3
    extraArgs:
      - -config.expand-env=true
  write:
    replicas: 3
    extraArgs:
      - -config.expand-env=true
  ## Enable minio for loki storage.
  ## This spawns simple minio instance without any production ready configuration.
  ## For productive usage go through the minio configuration or setup external storage for loki.
  ##
  minio:
    enabled: true
  ## Monitoring section has been deprecated by the loki project.
  ## ref: https://github.com/grafana/loki/blob/main/production/helm/loki/values.yaml#L3209
  ## As a replacement Loki suggests https://github.com/grafana/meta-monitoring-chart helm chart, but this chart can not
  ## be currently used as monitoring only deployment chart, see https://github.com/grafana/meta-monitoring-chart/issues/130.
  ## Hence, we should stick with this deprecated values for now.
  monitoring:
    dashboards:
      enabled: true
      labels:
        grafana_dashboard: "1"
    rules:
      enabled: true
      labels:
        prometheus_rule: "1"
    serviceMonitor:
      enabled: true
      labels:
        release: kubernetes-monitoring-servicemonitor
  ## Safety values for zero out replica counts of other Loki deployment modes
  ##
  singleBinary:
    replicas: 0
  ingester:
    replicas: 0
  querier:
    replicas: 0
  queryFrontend:
    replicas: 0
  queryScheduler:
    replicas: 0
  distributor:
    replicas: 0
  compactor:
    replicas: 0
  indexGateway:
    replicas: 0
  bloomCompactor:
    replicas: 0
  bloomGateway:
    replicas: 0
######################################################################################################################
##
## Promtail sub-chart configuration
##
## ref: https://github.com/grafana/helm-charts/tree/main/charts/promtail
## Note: if you observe failing promtail container due to "too many open files" error, check
##  the following issue https://github.com/grafana/loki/issues/1153 and increase the number of inotify
##  resources, e.g. see  https://www.suse.com/support/kb/doc/?id=000020048
######################################################################################################################
promtail:
  enabled: true
  config:
    clients:
    - url: http://{{ .Release.Name }}-loki-gateway/loki/api/v1/push
      tenant_id: 1
  # !IMPORTANT: each cluster must have promtail external label 'cluster' with unique value.
  # This will be used as cluster discriminator when logs are aggregated on observer cluster.
  extraArgs:
    - -client.external-labels=cluster=observer-cluster

######################################################################################################################
##
## SSL-exporter sub-chart configuration
##
## ref: https://github.com/dNationCloud/ssl-exporter
######################################################################################################################
ssl-exporter:
  enabled: false
  serviceMonitor:
  #  We can enable the service monitor, because we have prometheus in our monitoring stack
    enabled: true

  # # SSL Exporter example config
  # # Configure external URLs to scrape
  #   externalTargets:
  #   - example.com:443
  # # Configure  kubernetes secrets to scrape
  #   secretTargets:
  # # e.g. all secrets across all namespaces
  #   - "*/*"
  # # Certificate files on control plane nodes
  #   fileTargets:
  # # Included in default values of ssl-exporter helm chart
  #   - "/etc/kubernetes/pki/**/*.crt"
  # # Certificates within kubeconfig files
  #   kubeconfigTargets:
  # # Included in default values of ssl-exporter helm chart
  #   - /etc/kubernetes/admin.conf

######################################################################################################################
##
## Prometheus-blackbox-exporter sub-chart configuration
##
## ref: https://github.com/prometheus-community/helm-charts/tree/main/charts/prometheus-blackbox-exporter
######################################################################################################################
prometheus-blackbox-exporter:
  enabled: false
  releaseLabel: true
  prometheusRule:
    enabled: true
    additionalLabels:
      prometheus_rule: '1'
    rules:
    - alert: BlackboxProbeFailed
      expr: 'probe_success == 0'
      for: 5m
      labels:
        severity: critical
      annotations:
        message: 'Blackbox probe on target: {{ $labels.target }} failed'
    - alert: BlackboxSlowProbe
      expr: 'avg_over_time(probe_duration_seconds[1m]) > 5'
      for: 5m
      labels:
        severity: warning
      annotations:
        message: 'Blackbox probe on target: {{ $labels.target }} took more than 5s to complete, probe time = {{ $value }}'
    - alert: BlackboxSslCertificateWillExpireSoon
      expr: 'round((probe_ssl_earliest_cert_expiry - time()) / 86400, 0.1) < 30'
      for: 5m
      labels:
        severity: warning
      annotations:
        message: 'SSL certificate expires in {{ $value }} days'
  serviceMonitor:
    enabled: true
#    targets:
#    - name: dnation-cloud
#      url: https://dnation.cloud/

######################################################################################################################
##
## Openshift configuration
##
######################################################################################################################
openshift:
  # Set to true if you use openshift cluster
  enabled: false
  # If null, the helmchart creates a new scc
  existingSecurityContextConstraints: null
  # Service accounts that kubernetes monitoring stack uses
  serviceAccounts: []

######################################################################################################################
##
## Extras
##
######################################################################################################################
extraServices: []
  # - name: addservice
  #   namespace: targetnamespace
  #   ports:
  #   - name: portname
  #     port: portnumber
  #     targetPort: portnumber
  #   selector:
  #     app: app
  #   type: ClusterIP

extraSecrets: []
  # - name: addsecret
  #   data:
  #     auth-extra-groups: auth_group
  #     expiration: exp
  #     token-id: idtoken

extraCertificates: []
  # - name: newCertificate
  #   secretName: name
  #   issuer: issuer
  #   commonName: common_name
  #   hosts:
  #   - www.aaa.bb

extraConfigmaps: []
  # - name: load-configmap
  #   data:
  #     load_configmap.json: |-
  #       {
  #         ...
  #       }

############################################## WARNING ###############################################################
##
## DEPRECATED VALUES
##
## The following values are deprecated and will be removed in a future version of the helm chart!
############################################## WARNING ##############################################################

######################################################################################################################
##
## Loki-distributed sub-chart configuration
##
## ref: https://github.com/grafana/helm-charts/tree/main/charts/loki-distributed
## This chart is deprecated and replaced by [loki](https://github.com/grafana/loki/tree/main/production/helm/loki) helm chart.
## Loki helm chart is the only helm chart you should use for loki helm deployment. It supports loki deployment in monolithic, scalable
## and even [distributed mode](https://grafana.com/docs/loki/next/setup/install/helm/install-microservices/).
##
## We recommend use the loki helm chart for all fresh installations. If you already use loki-distributed helm chart, check
## the migration [guide](https://grafana.com/docs/loki/latest/setup/migrate/migrate-from-distributed/).
######################################################################################################################
loki-distributed:
  enabled: false
  loki:
    schemaConfig:
      configs:
        - from: 2020-09-07
          store: boltdb-shipper
          object_store: aws
          schema: v11
          index:
            prefix: loki_index_
            period: 24h
    storageConfig:
      boltdb_shipper:
        shared_store: aws
      aws:
        s3: "s3://access_key:secret_access_key@custom_endpoint/bucket_name"
        s3forcepathstyle: true  # set to 'false' to enable virtual-hosted-style URLs

prometheus-openstack-exporter:

  ## Set to to true if you want to use Openstack exporter
  enabled: false

  ## Disable OpenStack exporter multicloud mode
  ##
  multicloud:
    enabled: false
