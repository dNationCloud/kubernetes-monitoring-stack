#
# Copyright 2020 The dNation Kubernetes Monitoring Stack Authors. All Rights Reserved.
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Default values for dNation Kubernetes Monitoring Stack.
# Declare variables to be passed into helm chart dependencies.

## Override the default value of 'app' label used by k8s objects
##
nameOverride: ""

## Override the deployment namespace
##
namespaceOverride: ""

## Provide a name to substitute for the full names of resources
##
fullnameOverride: ""

## Deploy a dnation-kubernetes-monitoring
## ref: https://github.com/dNationCloud/kubernetes-monitoring
##
dnation-kubernetes-monitoring:
  enabled: true

  ## Deploy a Grafana dashboards and Prometheus rules for cluster monitoring
  ##
  clusterMonitoring:
    enabled: true

  ## Label of Grafana dashboard resource used for target discovery
  ##
  grafanaDashboards:
    labelGrafana:
      grafana_dashboard: '1'

  ## Label of Prometheus rule resource used for target discovery
  ##
  prometheusRules:
    labelPrometheus:
      prometheus_rule: '1'

## Deploy a loki
## ref: https://github.com/grafana/helm-charts/tree/main/charts/loki
##
loki:
  enabled: true

## Deploy a loki-distributed
## with s3-compatible object storage
## ref: https://github.com/grafana/helm-charts/tree/main/charts/loki-distributed
##
loki-distributed:
  enabled: false
  loki:
    schemaConfig:
      configs:
        - from: 2020-09-07
          store: boltdb-shipper
          object_store: aws
          schema: v11
          index:
            prefix: loki_index_
            period: 24h
    storageConfig:
      boltdb_shipper:
        shared_store: aws
      aws:
        s3: "s3://access_key:secret_access_key@custom_endpoint/bucket_name"
        s3forcepathstyle: true  # set to 'false' to enable virtual-hosted-style URLs

# Deploy a promtail
## ref: https://github.com/grafana/helm-charts/tree/main/charts/promtail
##
promtail:
  enabled: true
  config:
    lokiAddress: "http://{{ .Release.Name }}-loki:3100/loki/api/v1/push"

## Deploy a kube-prometheus-stack
## ref: https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack
##
kube-prometheus-stack:
  enabled: true

  ## Provide a name to substitute for the full names of resources
  ##
  fullnameOverride: kube-prometheus

  ## Default rules for monitoring the cluster
  ##
  defaultRules:
    ## Labels for default rules
    ##
    labels:
      prometheus_rule: '1'

    ## Disable some kube-prometheus-stack default rules
    ## They are replaced by rules in the kubernetes monitoring project
    ##
    rules:
      general: false
      kubernetesStorage: false

    ## Add custom rule label
    ##
    additionalRuleLabels:
      alertgroup: Cluster

  ## Deploy a Prometheus instance
  ##
  prometheus:
    prometheusSpec:
      ## PrometheusRules to be selected for target discovery
      ##
      ruleSelector:
        matchLabels:
          prometheus_rule: '1'

  ## Component scraping scheduler
  ## ref: https://dnationcloud.github.io/kubernetes-monitoring/helpers/FAQ/#kubernetes-monitoring-shows-down-state-for-some-control-plane-components-are-control-plane-components-working-correctly
  ##
  kubeScheduler:
    service:
      port: 10259
      targetPort: 10259
    serviceMonitor:
      https: true
      ## Skip TLS certificate validation when scraping
      # insecureSkipVerify: true
      ## Name of the server to use when validating TLS certificate
      # serverName: null

  ## Component scraping controller manager
  ## ref: https://dnationcloud.github.io/kubernetes-monitoring/helpers/FAQ/#kubernetes-monitoring-shows-down-state-for-some-control-plane-components-are-control-plane-components-working-correctly
  ##
  kubeControllerManager:
    service:
      port: 10257
      targetPort: 10257
    serviceMonitor:
      https: true
      ## Skip TLS certificate validation when scraping
      # insecureSkipVerify: true
      ## Name of the server to use when validating TLS certificate
      # serverName: null

  ## Component scraping etcd
  ##
  kubeEtcd:
    ## Etcd service
    ## ref: https://dnationcloud.github.io/kubernetes-monitoring/helpers/FAQ/#kubernetes-monitoring-shows-down-state-for-some-control-plane-components-are-control-plane-components-working-correctly
    ##
    service:
      port: 2381
      targetPort: 2381

  ## Configuration for prometheus-node-exporter subchart
  ##
  prometheus-node-exporter:
    ## Extra args extended with `rootfs`, `squashfs` and `nsfs` file systems
    ## For default extra args see ref: https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/values.yaml#L1220
    ##
    extraArgs:
      - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+)($|/)
      - --collector.filesystem.ignored-fs-types=^(rootfs|squashfs|nsfs|autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$

  ## Deploy a Grafana instance
  ##
  grafana:
    adminUser: "admin"
    adminPassword: "pass"
    ## Deploy default dashboards
    ##
    defaultDashboardsEnabled: false

    ## Define security context of grafana container
    ##
    securityContext:
      runAsUser: 0
      runAsGroup: 0
      fsGroup: 0

    ## Define command to be executed at startup of grafana container
    ##
    command:
    - "/bin/sh"
    - "-c"
    - "/etc/secrets/dnation_brand.sh && /run.sh"

    ## Inject dNation branding
    ##
    extraConfigmapMounts:
    - name: dnation-logo
      mountPath: /usr/share/grafana/public/img/dnation_logo.svg
      subPath: dnation_logo.svg
      configMap: dnation-logo
    - name: dnation-home
      mountPath: /usr/share/grafana/public/dashboards/home.json
      subPath: home.json
      configMap: dnation-home
    extraSecretMounts:
    - name: dnation-brand
      mountPath: /etc/secrets
      secretName: dnation-brand
      defaultMode: 0755

    ## Sidecar that collects the configmaps with specified label and stores them into the respective folders
    ##
    sidecar:
      dashboards:
        label: grafana_dashboard
        folder: /var/lib/grafana/dashboards/dnation
        provider:
          name: 'dNation'
          folder: 'dNation'
          disableDeletion: false
          allowUiUpdates: true
          editable: true
      datasources:
        label: grafana_datasource
        defaultDatasourceEnabled: false

    ## Configure additional grafana datasources
    ## ref: http://docs.grafana.org/administration/provisioning/#datasources
    ##
    additionalDataSources:
    - name: cluster-metrics
      isDefault: false
      type: prometheus
      url: "http://kube-prometheus-prometheus:9090"
      jsonData:
        httpMethod: POST
    - name: cluster-logs
      isDefault: false
      type: loki
      url: "http://{{ .Release.Name }}-loki:3100"
    - name: cluster-alerts
      isDefault: false
      type: camptocamp-prometheus-alertmanager-datasource
      url: "http://kube-prometheus-alertmanager:9093"
      jsonData:
        severity_critical: critical
        severity_high: high
        severity_warning: warning
        severity_info: info
    plugins:
    - camptocamp-prometheus-alertmanager-datasource 1.0.0
    - grafana-polystat-panel

  ## Deploy an Alertmanager instance
  ##
  alertmanager:
    config:
      route:
        receiver: 'null'
        routes:
        - match:
            alertname: Watchdog
          receiver: 'null'
      inhibit_rules:
      - source_match:
          severity: 'critical'
        target_match:
          severity: 'warning'
        equal: ['alertname']

extraServices: []
  # - name: addservice
  #   namespace: targetnamespace
  #   ports:
  #   - name: portname
  #     port: portnumber
  #     targetPort: portnumber
  #   selector:
  #     app: app
  #   type: ClusterIP

extraSecrets: []
  # - name: addsecret
  #   data:
  #     auth-extra-groups: auth_group
  #     expiration: exp
  #     token-id: idtoken

extraCertificates: []
  # - name: newCertificate
  #   secretName: name
  #   issuer: issuer
  #   commonName: common_name
  #   hosts:
  #   - www.aaa.bb

extraConfigmaps: []
  # - name: load-configmap
  #   data:
  #     load_configmap.json: |-
  #       {
  #         ...
  #       }
